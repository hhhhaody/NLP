{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pr2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYXRy1TiNWJi"
      },
      "source": [
        "import spacy\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "# !pip install bcolz\n",
        "import bcolz"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfMbaaaERvZI"
      },
      "source": [
        "# read files\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/prideAndPrejudice.txt','r') as f:\n",
        "  text = [line.rstrip('\\n') for line in f]\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/test_1.txt','r') as f:\n",
        "  test1 = [line.rstrip('\\n') for line in f]\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/test_2.txt','r') as f:\n",
        "  test2 = [line.rstrip('\\n') for line in f]\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/tweet.txt','r') as f:\n",
        "  tweet = [line.rstrip('\\n') for line in f] "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnxmWE5sULPV"
      },
      "source": [
        "# preprocess\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "dics = Counter()\n",
        "processed = []\n",
        "for i in text:\n",
        "  doc = nlp(i)\n",
        "  sents = [sent.text for sent in doc.sents]\n",
        "  for j in sents:\n",
        "    doc = nlp(j)\n",
        "    tokens = [token.text.lower() for token in doc]\n",
        "    padded = ['<s>'] + tokens + ['</s>']\n",
        "    dics.update(padded)\n",
        "    processed += [padded]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrSENiVrVrvD"
      },
      "source": [
        "# build vocabulary and mappings\n",
        "vocab = {k:v for k,v in dics.items() if v>1}\n",
        "vocab = sorted(vocab,key=vocab.get, reverse=True)\n",
        "vocab = ['_PAD','_UNK']+vocab\n",
        "word2idx = {o:i for i,o in enumerate(vocab)}\n",
        "idx2word = {i:o for i,o in enumerate(vocab)}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgsFZofAZ5Mg"
      },
      "source": [
        "# convert token sequences to integer sequences\n",
        "def convert(text, mapping, vocab, seq_len = 5):\n",
        "  sequences = []\n",
        "  for sentence in text:\n",
        "    if len(sentence) < seq_len:\n",
        "      sequences += [[mapping[word] if word in vocab or word in ['_PAD','_UNK','<s>','</s>'] else mapping['_UNK'] for word in sentence] + [0]*(seq_len-len(sentence))]\n",
        "    else:\n",
        "      sequences += [[mapping[word] if word in vocab or word in ['_PAD','_UNK','<s>','</s>'] else mapping['_UNK'] for word in sentence]]\n",
        "  return sequences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kDUnQFljMui"
      },
      "source": [
        "# create sequences of length 5 tokens\n",
        "def create_seq(text, seq_len = 5):\n",
        "    sequences = []\n",
        "    # if the number of tokens in 'text' is greater than 5\n",
        "    if len(text) > seq_len:\n",
        "      for i in range(seq_len, len(text)+1):\n",
        "        # select sequence of tokens\n",
        "        seq = text[i-seq_len:i]\n",
        "        # add to the list\n",
        "        sequences += [seq]\n",
        "      return sequences\n",
        "    # if the number of tokens in 'text' is less than or equal to 5\n",
        "    else:\n",
        "      return [text]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXTa-M0Vm-i8"
      },
      "source": [
        "def in_out_data(text, mapping, vocab, seq_len = 5):\n",
        "  data = convert(text, mapping, vocab, seq_len =seq_len)\n",
        "  seqs = [create_seq(i,seq_len=seq_len) for i in data]\n",
        "  seqs = sum(seqs,[])\n",
        "\n",
        "  # create inputs and targets (x and y)\n",
        "  x = []\n",
        "  y = []\n",
        "\n",
        "  for s in seqs:\n",
        "    x.append(s[:-1])\n",
        "    y.append(s[1:])\n",
        "\n",
        "  return np.array(x),np.array(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWDmTnZgnIj6"
      },
      "source": [
        "def get_batches(arr_x, arr_y, batch_size):\n",
        "         \n",
        "    # iterate through the arrays\n",
        "    prv = 0\n",
        "    for n in range(batch_size, arr_x.shape[0], batch_size):\n",
        "      x = arr_x[prv:n,:]\n",
        "      y = arr_y[prv:n,:]\n",
        "      prv = n\n",
        "      yield x, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYfV0jPCx4hV"
      },
      "source": [
        "class WordLSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab, pretrain = None, n_hidden=256, n_layers=4, drop_prob=0.3, lr=0.001):\n",
        "        super().__init__()\n",
        "\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        self.lr = lr\n",
        "        \n",
        "        if pretrain is None:\n",
        "          self.emb_layer = nn.Embedding(len(vocab), 200)\n",
        "\n",
        "          ## define the LSTM\n",
        "          self.lstm = nn.LSTM(200, n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "          ## define the fully-connected layer\n",
        "          self.fc = nn.Linear(n_hidden, len(vocab))\n",
        "        else:\n",
        "          (num,d) = pretrain.shape\n",
        "          self.emb_layer = nn.Embedding.from_pretrained(torch.from_numpy(pretrain).float(),freeze=False)\n",
        "\n",
        "          ## define the LSTM\n",
        "          self.lstm = nn.LSTM(d, n_hidden, n_layers, \n",
        "                              dropout=drop_prob, batch_first=True)\n",
        "          ## define the fully-connected layer\n",
        "          self.fc = nn.Linear(n_hidden, num)\n",
        "        \n",
        "        ## define a dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "\n",
        "        ## pass input through embedding layer\n",
        "        embedded = self.emb_layer(x)     \n",
        "        \n",
        "        ## Get the outputs and the new hidden state from the lstm\n",
        "        lstm_output, hidden = self.lstm(embedded, hidden)\n",
        "        \n",
        "        ## pass through a dropout layer\n",
        "        out = self.dropout(lstm_output)\n",
        "        \n",
        "        #out = out.contiguous().view(-1, self.n_hidden) \n",
        "        out = out.reshape(-1, self.n_hidden) \n",
        "\n",
        "        ## put \"out\" through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # return the final output and the hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        # if GPU is available\n",
        "        if (torch.cuda.is_available()):\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        \n",
        "        # if GPU is not available\n",
        "        else:\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wERlEf_ynGd"
      },
      "source": [
        "def train(net, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n",
        "    \n",
        "    # optimizer\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    \n",
        "    # loss\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # push model to GPU\n",
        "    net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    for e in range(epochs):\n",
        "\n",
        "        # initialize hidden state\n",
        "        h = net.init_hidden(batch_size)\n",
        "        \n",
        "        for x, y in get_batches(x_int, y_int, batch_size):\n",
        "            counter+= 1\n",
        "            \n",
        "            # convert numpy arrays to PyTorch arrays\n",
        "            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "            \n",
        "            # push tensors to GPU\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # detach hidden states\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero accumulated gradients\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get the output from the model\n",
        "            output, h = net(inputs, h)\n",
        "            \n",
        "            # calculate the loss and perform backprop\n",
        "            loss = criterion(output, targets.view(-1))\n",
        "\n",
        "            # back-propagate error\n",
        "            loss.backward()\n",
        "\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "\n",
        "            # update weigths\n",
        "            opt.step()            \n",
        "            \n",
        "            # if counter % print_every == 0:\n",
        "            \n",
        "              # print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "              #       \"Step: {}...\".format(counter))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkO30zVUyNJy"
      },
      "source": [
        "# predict next token\n",
        "def predict(net, tkn, h=None):\n",
        "         \n",
        "  # tensor inputs\n",
        "  x = np.array([[word2idx[tkn]]])\n",
        "  inputs = torch.from_numpy(x)\n",
        "  \n",
        "  # push to GPU\n",
        "  inputs = inputs.cuda()\n",
        "\n",
        "  # detach hidden state from history\n",
        "  h = tuple([each.data for each in h])\n",
        "\n",
        "  # get the output of the model\n",
        "  out, h = net(inputs, h)\n",
        "\n",
        "  # get the token probabilities\n",
        "  p = F.softmax(out, dim=1).data\n",
        "\n",
        "  p = p.cpu()\n",
        "\n",
        "  p = p.numpy()\n",
        "  p = p.reshape(p.shape[1],)\n",
        "\n",
        "  # get indices of top 3 values\n",
        "  top_n_idx = p.argsort()[-3:][::-1]\n",
        "\n",
        "  # randomly select one of the three indices\n",
        "  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n",
        "\n",
        "  # return the encoded value of the predicted char, the hidden state, \n",
        "  # and the probability distribution of the predicted token\n",
        "  return idx2word[sampled_token_index], h , p\n",
        "\n",
        "\n",
        "# function to generate text\n",
        "def sample(net, prime='<s>'):\n",
        "        \n",
        "    # push to GPU\n",
        "    net.cuda()\n",
        "    \n",
        "    net.eval()\n",
        "\n",
        "    # batch size is 1\n",
        "    h = net.init_hidden(1)\n",
        "\n",
        "    toks = prime.split()\n",
        "\n",
        "    # predict next token\n",
        "    for t in prime.split():\n",
        "      token, h , _ = predict(net, t, h)\n",
        "    \n",
        "    toks.append(token)\n",
        "\n",
        "    while True:\n",
        "      token, h , _ = predict(net, toks[-1], h)\n",
        "      toks.append(token)\n",
        "      if token == '</s>':\n",
        "        break\n",
        "\n",
        "\n",
        "    return ' '.join(toks)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T0-dMHiynsN",
        "outputId": "98eab22a-64d7-4c95-d753-f81851338a3e"
      },
      "source": [
        "x_int,y_int = in_out_data(processed,word2idx,vocab)\n",
        "net1 = WordLSTM(vocab)\n",
        "net1.cuda()\n",
        "print(net1)\n",
        "train(net1, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(3913, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3913, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-WF02zFzsFc"
      },
      "source": [
        "torch.save(net1.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net1')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY_bEF5hSP--"
      },
      "source": [
        "2.1: Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HjQ0YqWzvC-",
        "outputId": "21a367e3-38c7-4997-a4a2-f52878891abd"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net1))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> \" you must not have _UNK the subject of her own , she could be prevailed to her husband and lydia , though he was gone in her way to be _UNK , by the world ; and , though the _UNK and her husband was _UNK by the _UNK . </s>\n",
            "<s> she had no longer to speak for his _UNK . ' that he had been so well as they had gone to longbourn . \" said she , as soon , i hope you are mistaken . ' you will be a _UNK thing , and she could be in a similar _UNK to be sure ! \" </s>\n",
            "<s> i have no notion of the subject , she was not so far as she had ever inspired at her with her _UNK , and she had been _UNK , by her nephew , who had given her , when her marriage had been _UNK , she dropt all the room , was in a different room . ' she is very much , and i hope it was to get a sheet of _UNK and her daughter , she had been so happy at the same _UNK . \" cried she was not to the library ; but , as she could not be so much as she was in a few days at the door , she was not to the library , she was almost ashamed , that her mother 's letter and _UNK and her husband , and she had no pleasure to the lakes , she was not quite a year , and she could be in her power , she had not yet been _UNK and unreserved , she was not to be happy . \" cried she was quite ignorant , that you have given him so happy as to be so tiresome at the end , and the two sisters were in her own , and her manners , she had not been so fortunate at her own room ; but , as she could not help feeling a _UNK to be _UNK , by the _UNK , she had not been a year ; for she had been in her power to make her more elegant than the comfort to the young man who , though he was not so happy from netherfield ; for , and _UNK of his _UNK , and she was not to be sure , she had been so happy from her sisters ; and , in a _UNK , explained for her own , she was not so far from the _UNK of his wife ; and as they had been _UNK , she could not have a _UNK and her sisters , and her manners were _UNK and anxious , and she could not be prevailed on for his wife , who had given them a second time . ' </s>\n",
            "<s> i was not to find that you were not afraid of the subject , and _UNK her husband , who was not so happy at the same _UNK , she was very _UNK . \" cried elizabeth . \" i have not yet , i was sure , and you shall be so silly , and you are to be sure ! \" said she ; and , \" i have no notion but i was not to be sure ! ' </s>\n",
            "<s> \" oh ; \" you have been very much to do . \" i do you think i am afraid i was always silly , i am quite afraid of her mother 's , to her husband and elizabeth , though she had no pleasure to her sister and elizabeth , and the comfort to her husband and her daughters were in her own room ; for she could not have been in town ; and as she was now in a neighbouring county , which was _UNK to his friend , and she could have a most _UNK and _UNK of the _UNK , was _UNK by his _UNK and _UNK , and _UNK of the _UNK of her family ; but , as well as they had not been so happy from netherfield , she was not to her , and the two sisters were in her way with her , she could be in a few minutes at her own feelings . ' she is very little longer ; for the sake to be so much as to be _UNK . \" said he ; \" but , though you will not help writing you so much to say , \" i have been a very fine creature . \" </s>\n",
            "<s> she could not help saying that he could be a very good humour in derbyshire , which , in the world , she could be in a way , she had been a very good , _UNK , to be sure . \" </s>\n",
            "<s> i am sure you have given him the _UNK , but i have been so much as she could not be prevailed on of her husband 's _UNK to elizabeth , \" she added . </s>\n",
            "<s> i have been the _UNK of her mother 's , she could have been obliged to _UNK , and her husband was not so well mortified , she could not help laughing in london . ' that you have given you , \" replied her mother 's sake , and i have been very glad to be _UNK in the _UNK . </s>\n",
            "<s> \" oh ; and , and the remaining a letter , she was quite _UNK , she could not have a most _UNK _UNK , was in her power to make him the _UNK of the room ; for , in a _UNK of her own , though she had been a year , and she could be very well at the end , and she could be so happy from her sisters ; for she could be a _UNK to be _UNK , and her husband , and she had not been so happy as to make him so little as if he was now so well as they had been _UNK to the door , which , and she could have been in her power to see him , \" said she . \" </s>\n",
            "<s> \" oh , lord , i have been so well _UNK as i am sure she will not have a good humour , to the advantage , and her manners suffered , but the sake to her husband , \" she added . ' that he was gone in a different humour . \" cried mrs. gardiner . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk_cvL-nLKX5"
      },
      "source": [
        "# calculate the probability for a test sentence\n",
        "def prob4sent(text,net,vocab):\n",
        "  sentence = text.split()\n",
        "  h = net.init_hidden(1)\n",
        "  prob = np.log(1/len(vocab))\n",
        "  for i in range(len(sentence)-1):\n",
        "    prev = sentence[i] if sentence[i] in vocab else '_UNK'\n",
        "    pred = sentence[i+1] if sentence[i+1] in vocab else '_UNK'\n",
        "    _, h, p = predict(net, prev, h)\n",
        "    prob += np.log(p[word2idx[pred]])\n",
        "  # return the probability and the number of words in the sentence\n",
        "  return prob,len(sentence)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a8uMsc0Me6o"
      },
      "source": [
        "# calculate perplexity\n",
        "def perplexity(test,net,vocab):\n",
        "  N,res = 0,0\n",
        "  for i in test:\n",
        "    p, n = prob4sent(i,net,vocab)\n",
        "    N+=n\n",
        "    res+=p\n",
        "  return np.e**(-1/N*res)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YVoVlKQSanZ"
      },
      "source": [
        "2.2 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzQb7ToM3G6q",
        "outputId": "cb14c0b1-0c43-459d-b02f-3ca193ca2e9b"
      },
      "source": [
        "p = perplexity(test1,net1,vocab)\n",
        "print('The perplexity for part 2.2 is', p)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.2 is 157.4577520315396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB5lyvXENefh",
        "outputId": "067d096e-0e01-4999-c517-1a432dbb7df3"
      },
      "source": [
        "# with seq_len 25\n",
        "x_int,y_int = in_out_data(processed,word2idx,vocab,seq_len=25)\n",
        "net2 = WordLSTM(vocab)\n",
        "net2.cuda()\n",
        "print(net2)\n",
        "train(net2, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(3913, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3913, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIiHmrRPVZK6"
      },
      "source": [
        "torch.save(net2.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net2')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYFkoCSPSgkj"
      },
      "source": [
        "2.3 Output <br>\n",
        "We can see that the outputs are longer than before with less UNKs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YzwVxOEa7Xh",
        "outputId": "6ae74589-02cc-45af-881d-245f05e12201"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net2))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> \" i am not to say you will not be in company . </s>\n",
            "<s> i can never help laughing . </s>\n",
            "<s> i shall not have _UNK so much as i ought for the trouble that must become up it ; and i shall have hated you at pemberley . ' , and she had not seen that she had not seen the place ; though , though the sake of her nephew 's letter ; though , in spite of every thing ; though , in quitting her almost the substance of mr. bennet and myself with a few struggles to derbyshire , and was very much awe and _UNK in his own , he was now anxious that her own opinion , relating the _UNK which might be always flying so much in her family ; and as they changed the occasion , in a _UNK _UNK of the season and two , tax in a letter from the _UNK of his meetings , instead of his meetings that her husband had not been spent in his own , he had always been ashamed of him , unless she could hardly see the _UNK , in spite that his manners was always so insufficient ; and , after return to her husband ' _UNK . ' of the room ; though she looked down with delight in a _UNK , which was very insufficient , she was at the same man in which they were going from her own room , and the uncomfortable feelings arising with its rest . \" cried you , \" replied her sister , as well in the room ; \" but you are to find it at all , i hope you ought , and in the mean course that i am now married . \" cried you , \" said elizabeth -- colouring by the future which she might have hated them to her ; but , though she had not been able in seeing him at longbourn . \" </s>\n",
            "<s> \" you will have been so silly ? </s>\n",
            "<s> \" i am afraid , you are to see yourself ; and i am not married , i am convinced it will have done to you at all , i shall not tell me for her , \" replied she , as you have , \" replied her mother , \" i beg myself . \" i am sure you are not married , and you are to say that i was to say you may be as little at all ; and , though i shall not be gone with so _UNK . ' </s>\n",
            "<s> \" you have not seen me to be selfish of my life , \" cried her husband ; but i am not convinced that he will be so happy , and i am afraid that your sister was so much _UNK by the season and _UNK , and was now the smallest objection in their support , she dropt no more _UNK . ' </s>\n",
            "<s> i am sure i shall be to see me . ' </s>\n",
            "<s> \" in the bye , i hope it will have been a simpleton . ' , she had no time to see it from the familiarity which her affection would be equally _UNK acquainted by the familiarity which she had dropt himself ; but as they were at the same means of going with her . </s>\n",
            "<s> i can not expect , i hope it will be so glad to see you with her own children . ' of her life . \" </s>\n",
            "<s> i shall be in the same kind to be prevented by her own feelings ; and i am afraid that i ought of the evening , and live to see the rest of the rest of the _UNK of the _UNK which she ventured to see that he might converse in every place , she sent her in her _UNK , though she began for the same time with a forbearance of inferior reflection , she sent it on her _UNK , which she might have been impossible for them in her affection for him , or the direction of delight with the rest of the world ; but , after all his _UNK in his life ; and as the subject came from the season and _UNK which they ought to see that her husband were still handsomer enough for her to come with him , unless she was going by his own family ; though , as she had no pleasure in love , he was almost anxious for the _UNK and entreaty of her nephew . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lfieMn-cV9O"
      },
      "source": [
        "2.4 Perplexity "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VJO2R-hbP4K",
        "outputId": "c6a5ca7d-9307-4305-9d4d-637a574c795b"
      },
      "source": [
        "p = perplexity(test1,net2,vocab)\n",
        "print('The perplexity for part 2.4 is', p)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.4 is 250.72384241976118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HBfc8uzcwWi"
      },
      "source": [
        "2.5 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CdE5vXQezkc",
        "outputId": "10c81ef6-ed3d-4983-cb23-2732a55c2199"
      },
      "source": [
        "p = perplexity(test2,net1,vocab)\n",
        "print('The perplexity for part 2.5 is', p)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.5 is 779.7476435290162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtkuaXLTe9Y2"
      },
      "source": [
        "# words = []\n",
        "# idx = 0\n",
        "# word2idx = {}\n",
        "# vectors = bcolz.carray(np.zeros(1), rootdir=f'/content/drive/MyDrive/Colab Notebooks/6B.100.dat', mode='w')\n",
        "\n",
        "# with open(f'/content/drive/MyDrive/Colab Notebooks/glove.6B.100d.txt', 'rb') as f:\n",
        "#     for l in f:\n",
        "#         line = l.decode().split()\n",
        "#         word = line[0]\n",
        "#         words.append(word)\n",
        "#         word2idx[word] = idx\n",
        "#         idx += 1\n",
        "#         vect = np.array(line[1:]).astype(np.float)\n",
        "#         vectors.append(vect)\n",
        "    \n",
        "# vectors = bcolz.carray(vectors[1:].reshape((400000, 100)), rootdir=f'/content/drive/MyDrive/Colab Notebooks/6B.100.dat', mode='w')\n",
        "# vectors.flush()\n",
        "# pickle.dump(words, open(f'/content/drive/MyDrive/Colab Notebooks/6B.100_words.pkl', 'wb'))\n",
        "# pickle.dump(word2idx, open(f'/content/drive/MyDrive/Colab Notebooks/6B.100_idx.pkl', 'wb'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGrO1C5te1tD"
      },
      "source": [
        "vectors = bcolz.open(f'/content/drive/MyDrive/Colab Notebooks/6B.100.dat')[:]\n",
        "words = pickle.load(open(f'/content/drive/MyDrive/Colab Notebooks/6B.100_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'/content/drive/MyDrive/Colab Notebooks/6B.100_idx.pkl', 'rb'))\n",
        "\n",
        "glove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQP2st8SyF0W"
      },
      "source": [
        "vocab2 = ['_PAD','_UNK']+ list(dics.keys())\n",
        "word2idx = {o:i for i,o in enumerate(vocab2)}\n",
        "idx2word = {i:o for i,o in enumerate(vocab2)}\n",
        "matrix_len = len(vocab2)\n",
        "weights_matrix = np.zeros((matrix_len, 100))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(vocab2):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "        words_found += 1\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(100))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_9ZgvD-RbGV",
        "outputId": "07a279a7-65cc-464a-895f-4967326c3f62"
      },
      "source": [
        "x_int,y_int = in_out_data(processed,word2idx,glove.keys())\n",
        "net3 = WordLSTM(vocab2 ,pretrain = weights_matrix)\n",
        "net3.cuda()\n",
        "print(net3)\n",
        "train(net3, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(6378, 100)\n",
            "  (lstm): LSTM(100, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=6378, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX_zxlgVyvso"
      },
      "source": [
        "torch.save(net3.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net3')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL95-MdVc0ds"
      },
      "source": [
        "2.6 Output<br>\n",
        "We can see that in the output some phrases repeat a lot, for example 'I am afraid' and 'she had been'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1Aif_-cyWM-",
        "outputId": "e0c26fbe-a409-4747-ff3f-5273fdde83a2"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net3))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> she had not the pleasure which had happened , to her mother and elizabeth was in a whisper , she could be sure , and she could have relished an hour , or her own feelings was not so ungovernable a match . \" </s>\n",
            "<s> \" my dearest jane , \" said jane . </s>\n",
            "<s> she could not be so much , and the others of visiting into her own room . \" \" i am not afraid , i am afraid i am sure i have been to make him a very good young man of her sisters ; for , when she could be the case ; she had not yet been to the lakes . </s>\n",
            "<s> \" you must not give me the trouble which had done , but i shall be sure to get in her own private , sportive and consequence of his warmest sisters ; for elizabeth 's congratulations was to be in a whisper of her sisters . ' \" said elizabeth ; but i was sure , and the pains you may be so much , she was not deceived with the day . \" i was not afraid that he was to be a most anxious , and she could have hated you . \" said mrs. bennet . ' i have no improper more than i am not likely for a cheap , she could have hated her to her , to be a very selfish , hypocritical humour , she had always seen her , but the first of his warmest affection to elizabeth , and she had not yet been to her , and the two visits which her daughter had not the first vehemence of his warmest sisters , and her husband was still anxious for his wife 's vulgarity was a great comfort , she had been so happy , that she was so tiresome , and the establishment of the world . ' she had not been so well as she was not so happy . ' </s>\n",
            "<s> i am afraid , \" i do , and , perhaps , i am sure , \" said mrs. gardiner , \" i shall not have been to be sure , that i have not a great deal , to be sure to get in the neighbourhood , she was sitting from a cheap acquaintance . </s>\n",
            "<s> i was not afraid to speak , but i shall not have relished a vicinity to the match , she had no more more than her husband , and her manners , or bath ; and , as she was not so material an effect . \" i am afraid , \" cried elizabeth . </s>\n",
            "<s> she was sitting into her , but the _UNK was over , or the first of his ingratitude , she was still giving him the happiest of his wife 's behaviour for his sisters ; for the contents which she was acquainted with him to the night , she could be prevailed in her husband 's vulgarity was not very well mortified her to be a great comfort , she was still partial for his sisters ; and , as she was not to make the subject , she could not be properly sanctioned ; but she had no more more , and the others was in the world ; but elizabeth was almost applied to the advantage which her affection was soon drawn from her , she could be a most shooting , and she was in the course of his warmest daughters . ' </s>\n",
            "<s> \" i am afraid , i shall not be a sheet to give you to do to do . ' i was in town ; but she had been a very great deal , to her husband , and she was in a great deal to have done to her husband , she had not the most delightful , she could have been so much mortified by the match , she had not the most intimate man ; and she had been so well known to her , and her manners was not to be sure , to the lakes . ' i am afraid , i shall not be a sad , and she could be a very great deal , to her , she had been a great comfort , or the others was a most disagreeable young man . \" \" you may be a great comfort , and the _UNK of the world . </s>\n",
            "<s> \" my uncle is not likely , and the evening of her sister , and the persons was not to have a nice much more , to her own private room , she was sure of the first , she was sitting with him , to her own feelings ; for elizabeth , and the preference which she felt , she was necessarily relieved by his wife 's behaviour , she was so much , she could be sure of her husband was still moving up , she could have inspired to be sure to be a little longer in a humour of felicity and affection to the wife which the others was not so well as much to the advantage which elizabeth was prevailed to the lakes . \" i have not been so well . </s>\n",
            "<s> i am not likely to know how much you may have hated him to be , and she could be so much awe , she had been the most of his sisters ; but , whenever she was not a very insufficient , and the others of her own feelings and her daughter , to her , she could be sure , to be sure , and i shall not have the advantage of the world , she could not listen for her father , she was still anxious , and elizabeth , who was not in the course of his warmest affection , or the others , and her spirits was the happiest of the family of the evening ; for elizabeth , though elizabeth , who was the least creature else . \" said her father , as soon afterwards , \" that i was in the middle which i had been to be a little , and the others , she could have inspired to be , as well as her husband 's pleasantry . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLv7bBS6c21X"
      },
      "source": [
        "2.7 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZnIuIcSIIsY",
        "outputId": "25829ef6-20f1-486f-f6ed-e62dc40d0472"
      },
      "source": [
        "p = perplexity(test1,net3,vocab2)\n",
        "print('The perplexity for part 2.7 is', p)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.7 is 206.99343980793225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjQuSotzghzR"
      },
      "source": [
        "tweets = [i.split() for i in tweet]\n",
        "tdics = Counter()\n",
        "tdics.update(sum(tweets,[]))\n",
        "vocab3 = {k:v for k,v in tdics.items() if v>1}\n",
        "vocab3 = sorted(vocab3,key=vocab3.get, reverse=True)\n",
        "vocab3 = ['_PAD','_UNK']+vocab3\n",
        "word2idx = {o:i for i,o in enumerate(vocab3)}\n",
        "idx2word = {i:o for i,o in enumerate(vocab3)}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35mHRg0FkG0V",
        "outputId": "7a760bd9-2d39-42bd-bed3-f444b9c87889"
      },
      "source": [
        "x_int, y_int = in_out_data(tweets,word2idx,vocab3)\n",
        "net4 = WordLSTM(vocab3)\n",
        "net4.cuda()\n",
        "print(net4)\n",
        "train(net4, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(3997, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3997, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQN_tkYilGgN"
      },
      "source": [
        "torch.save(net4.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net4')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thqa86Hae3i6"
      },
      "source": [
        "2.8 Output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zywgehac545g",
        "outputId": "238bcc40-9c09-4106-df68-274893e31b6d"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net4))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> \" i 'm so sad </s>\n",
            "<s> i m not going back to work today . i miss my _UNK of my _UNK _UNK , but still a cutie ! ! </s>\n",
            "<s> _UNK thanks for my house </s>\n",
            "<s> \" i hate the hills , but i have to get to sleep ! i m _UNK . _UNK _UNK . </s>\n",
            "<s> _UNK thanks to _UNK . i m so tired and it is _UNK _UNK _UNK . \" </s>\n",
            "<s> i have a headache . \" i 'm sorry . please keep _UNK in _UNK _UNK . </s>\n",
            "<s> i have to be _UNK _UNK , i have to sleep in my house , and _UNK i 'm going a great arvo ! i have a _UNK _UNK _UNK _UNK , but it was like _UNK _UNK , i 'm going a good idea ! ! i m _UNK , but still going away to be _UNK , i have a _UNK _UNK . \" _UNK , _UNK , etc , i 'm not feeling a bit of the last day of my life ! i m so tired . \" i m _UNK . _UNK _UNK , etc , i 'm so hungry . </s>\n",
            "<s> \" </s>\n",
            "<s> _UNK i do nt want a new background for my _UNK . \" _UNK _UNK , _UNK , _UNK i 'm not going to get _UNK _UNK . _UNK _UNK . </s>\n",
            "<s> \" _UNK _UNK _UNK . i m sorry _UNK _UNK . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP392sr1fONp"
      },
      "source": [
        "2.9 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH48lGID6ATd",
        "outputId": "a2ccb623-1ab9-4cc7-9b1a-cabcae83b7e4"
      },
      "source": [
        "p = perplexity(test2,net4,vocab3)\n",
        "print('The perplexity for part 2.9 is', p)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.9 is 196.16600697827522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCbsQ97DJCwS",
        "outputId": "e621dae6-5b3f-401a-ecde-f6f1a2c9129f"
      },
      "source": [
        "x_int, y_int = in_out_data(tweets,word2idx,vocab3,seq_len=15)\n",
        "net5 = WordLSTM(vocab3)\n",
        "net5.cuda()\n",
        "print(net5)\n",
        "train(net5, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(3997, 200)\n",
            "  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=3997, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UZY8sgRJjWh"
      },
      "source": [
        "torch.save(net5.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net5')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji-UTr94fSd5"
      },
      "source": [
        "2.10 Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyQL5U_5JoRf",
        "outputId": "a15ddaf3-1c42-4387-9649-823a9b1fd8ee"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net5))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> _UNK _UNK i m a little bit at work at _UNK and _UNK . i 'm going to london my driver to go insane . </s>\n",
            "<s> \" _UNK _UNK i 'm so hungry . </s>\n",
            "<s> \" i 'm so hungry but i m a _UNK , but do n't wanna eat more ... but i 'm staying to sleep early . i 'm not a _UNK , and now it is not 1 - the _UNK _UNK , but i 'm staying to see my lakers . just _UNK _UNK _UNK . </s>\n",
            "<s> i have to be at the office . </s>\n",
            "<s> i 'm not a _UNK </s>\n",
            "<s> _UNK _UNK i have _UNK _UNK </s>\n",
            "<s> _UNK it was n't _UNK </s>\n",
            "<s> _UNK it is _UNK </s>\n",
            "<s> i m a pro day at _UNK _UNK </s>\n",
            "<s> i m going 2 bed again ! ! ! i m not _UNK ! ! </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHgkQ0jkfVHN"
      },
      "source": [
        "2.11 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxH8KIF4JsjK",
        "outputId": "8a9fd010-3dd7-40b5-c527-fdc9a7dcda5c"
      },
      "source": [
        "p = perplexity(test2,net5,vocab3)\n",
        "print('The perplexity for part 2.11 is', p)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.11 is 213.8682215870541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcRmWiFDfX9R"
      },
      "source": [
        "2.12 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTI4_fx1Mg6i",
        "outputId": "9da29735-edaa-4d63-fc85-7d0bd6f225e6"
      },
      "source": [
        "p = perplexity(test1,net4,vocab3)\n",
        "print('The perplexity for part 2.12 is', p)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.12 is 349.493321909592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Jree8AXPhU"
      },
      "source": [
        "vocab4 = ['_PAD','_UNK']+ list(tdics.keys())\n",
        "word2idx = {o:i for i,o in enumerate(vocab4)}\n",
        "idx2word = {i:o for i,o in enumerate(vocab4)}\n",
        "weights_matrix = np.zeros((len(vocab4), 100))\n",
        "for i, word in enumerate(vocab4):\n",
        "    try: \n",
        "        weights_matrix[i] = glove[word]\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(100))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FOD6U-qXhJF",
        "outputId": "a32942b8-4dd1-4a77-df4f-c5ba67011c0e"
      },
      "source": [
        "x_int,y_int = in_out_data(tweets,word2idx,glove.keys())\n",
        "net6 = WordLSTM(vocab4 ,pretrain = weights_matrix)\n",
        "net6.cuda()\n",
        "print(net6)\n",
        "train(net6, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(12632, 100)\n",
            "  (lstm): LSTM(100, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=12632, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzYcXLPyYm9X"
      },
      "source": [
        "torch.save(net6.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net6')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJL4c5-ZftBr"
      },
      "source": [
        "2.13 Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICCLGEv-Zj-u",
        "outputId": "2bbabb01-4689-4abd-e57d-d17182be325a"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net6))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> i have n't seen it to sleep ! </s>\n",
            "<s> i m going back back to school today </s>\n",
            "<s> \" amp i have a headache . </s>\n",
            "<s> \" _UNK _UNK ; _UNK i have n't been a bit day , but it is the only of my soul one . </s>\n",
            "<s> \" _UNK it is a bit day and _UNK . i m so hot ! </s>\n",
            "<s> \" i m so bummed i 'm not sure i have to go back back home , i ca nt sleep , i ca n't get to go out . but i ca nt sleep , but i 'm going a lot cleanser and locked . but i do not get to see my beaty - sort & \" </s>\n",
            "<s> \" amp _UNK _UNK - no one of me _UNK i have n't seen it . \" i 'm so bored ! i have to go to work . </s>\n",
            "<s> _UNK _ _ _UNK ) ) ) ) ) _UNK ; i have n't seen my _UNK ; _UNK _UNK _UNK i m not going out in the morning . \" _UNK well , i 'm so bored ! i m so sad ! </s>\n",
            "<s> i have to be a long note _UNK i 'm not going to sleep , and its not feeling going to sleep . </s>\n",
            "<s> \" i m going a _UNK i have a headache , but still a lot of the life . \" i m so sad ! ! i 'm so tired , but it 's not good ! i 'm a closet , but it is the bane in the 1980 - the first time to go back to the shark tooth weight one . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNxY9VcAfwLR"
      },
      "source": [
        "2.14 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD2FEMO6aKKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8009031-33d5-430e-9772-797afa6e1331"
      },
      "source": [
        "p = perplexity(test2,net6,vocab4)\n",
        "print('The perplexity for part 2.14 is', p)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.14 is 475.52951618365313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNSK6xocaZbc"
      },
      "source": [
        "# words = []\n",
        "# idx = 0\n",
        "# word2idx = {}\n",
        "# vectors = bcolz.carray(np.zeros(1), rootdir=f'/content/drive/MyDrive/Colab Notebooks/27B.100.dat', mode='w')\n",
        "\n",
        "# with open(f'/content/drive/MyDrive/Colab Notebooks/glove.twitter.27B.100d.txt', 'rb') as f:\n",
        "#     for l in f:\n",
        "#       line = l.decode().split()\n",
        "#       if idx == 38522:\n",
        "#         word = l.decode().split(' ')[0]\n",
        "#         vect = np.array(line).astype(np.float)\n",
        "#       else:\n",
        "#         word = line[0]\n",
        "#         vect = np.array(line[1:]).astype(np.float)\n",
        "#       words.append(word)\n",
        "#       word2idx[word] = idx\n",
        "#       idx += 1\n",
        "#       vectors.append(vect)\n",
        "    \n",
        "# vectors = bcolz.carray(vectors[1:].reshape((idx, 100)), rootdir=f'/content/drive/MyDrive/Colab Notebooks/27B.100.dat', mode='w')\n",
        "# vectors.flush()\n",
        "# pickle.dump(words, open(f'/content/drive/MyDrive/Colab Notebooks/27B.100_words.pkl', 'wb'))\n",
        "# pickle.dump(word2idx, open(f'/content/drive/MyDrive/Colab Notebooks/27B.100_idx.pkl', 'wb'))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lslpjQ4Ga13j"
      },
      "source": [
        "vectors = bcolz.open(f'/content/drive/MyDrive/Colab Notebooks/27B.100.dat')[:]\n",
        "words = pickle.load(open(f'/content/drive/MyDrive/Colab Notebooks/27B.100_words.pkl', 'rb'))\n",
        "word2idx = pickle.load(open(f'/content/drive/MyDrive/Colab Notebooks/27B.100_idx.pkl', 'rb'))\n",
        "\n",
        "twitterglove = {w: vectors[word2idx[w]] for w in words}"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45hNkaGmdxXb"
      },
      "source": [
        "vocab5 = ['_PAD','_UNK']+ list(tdics.keys())\n",
        "word2idx = {o:i for i,o in enumerate(vocab5)}\n",
        "idx2word = {i:o for i,o in enumerate(vocab5)}\n",
        "matrix_len = len(vocab5)\n",
        "weights_matrix = np.zeros((matrix_len, 100))\n",
        "words_found = 0\n",
        "\n",
        "for i, word in enumerate(vocab5):\n",
        "    try: \n",
        "        weights_matrix[i] = twitterglove[word]\n",
        "    except KeyError:\n",
        "        weights_matrix[i] = np.random.normal(scale=0.6, size=(100))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1hz9TB5eIvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceba6bd1-7c7a-441a-8ceb-4ec946126780"
      },
      "source": [
        "x_int,y_int = in_out_data(tweets,word2idx,twitterglove.keys())\n",
        "net7 = WordLSTM(vocab5 ,pretrain = weights_matrix)\n",
        "net7.cuda()\n",
        "print(net7)\n",
        "train(net7, batch_size = 32, epochs=20, print_every=256)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WordLSTM(\n",
            "  (emb_layer): Embedding(12632, 100)\n",
            "  (lstm): LSTM(100, 256, num_layers=4, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=12632, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SF8DAU2neXTu"
      },
      "source": [
        "torch.save(net7.state_dict(),'/content/drive/MyDrive/Colab Notebooks/net7')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gczpzlpff7AO"
      },
      "source": [
        "2.15 Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_pFCWN9edMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c853399-1379-403a-82ae-90a0d96dc8aa"
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample(net7))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> i have n't been sleeping in my house . i 'm not so hungry . </s>\n",
            "<s> _UNK _UNK _UNK \" </s>\n",
            "<s> \" </s>\n",
            "<s> i have a doctors _UNK . i 'm not feeling _UNK , i have to get a _UNK _UNK i m sad . \" _UNK hey nathan . </s>\n",
            "<s> _UNK i have n't been a long day _UNK </s>\n",
            "<s> i m not _UNK _UNK _UNK _UNK i m sad . i m so sad . i 'm going _UNK i 'm not looking forward on a bunch of my house . \" i 'm going to sleep tomorrow . </s>\n",
            "<s> i have to be _UNK % over , but still _UNK _UNK i have n't seen the hills . </s>\n",
            "<s> _UNK i m sorry for a great note _UNK i 'm sorry i 'm not a closet drf bar in my morning . i m broke to do resin - asti </s>\n",
            "<s> \" _UNK _UNK , i 'm not feeling _UNK % _UNK _UNK _UNK i 'm going on my state , i 'm gon na be _UNK i have to be _UNK % _UNK , _UNK i m stacey is a lot ! </s>\n",
            "<s> _UNK i m sorry for the life , and _UNK , i 'm sorry i have n't quit a lot of the _UNK _UNK ; _UNK i have n't seen my nokia deflating , and it 's not a long note , i have to do wid ! ! ! ! </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8cwNfVf9R4"
      },
      "source": [
        "2.16 Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IS7mei4ehqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2694be6-a597-4ee3-c6fe-74081ad3747c"
      },
      "source": [
        "p = perplexity(test2,net7,vocab5)\n",
        "print('The perplexity for part 2.16 is', p)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The perplexity for part 2.16 is 585.9613341401835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CciI1sArEY4F"
      },
      "source": [
        ""
      ],
      "execution_count": 51,
      "outputs": []
    }
  ]
}